{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Learning to Extract Pain Outcomes from Clinical Text without Labeled Data\n",
    "## II: Generative Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numba\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "#matplotlib.rcParams['figure.figsize'] = (18,6)\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.learning.disc_models.rnn import *\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel.models import candidate_subclass, Document, Sentence, Candidate, Span\n",
    "from snorkel.learning import GenerativeModel\n",
    "from extractlib.labelers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling Functions n=24\n"
     ]
    }
   ],
   "source": [
    "session = SnorkelSession()\n",
    "\n",
    "try:\n",
    "    PainLocation = candidate_subclass('PainLocation', ['pain', 'anatomy'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "relation = PainLocationRelation(dict_root=\"../data/\")\n",
    "print \"Labeling Functions n={}\".format(len(relation.lfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Candidates and Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold [TRAIN] 224\n",
      "Gold [DEV]   63\n",
      "Gold [TEST]  165\n"
     ]
    }
   ],
   "source": [
    "train_cands = session.query(Candidate).filter(Candidate.split == 0).order_by(Candidate.id).all()\n",
    "dev_cands   = session.query(Candidate).filter(Candidate.split == 1).order_by(Candidate.id).all()\n",
    "test_cands  = session.query(Candidate).filter(Candidate.split == 2).order_by(Candidate.id).all()\n",
    "\n",
    "L_gold_train = load_gold_labels(session, split=0, annotator_name='gold')\n",
    "L_gold_dev   = load_gold_labels(session, split=1, annotator_name='gold')\n",
    "L_gold_test  = load_gold_labels(session, split=2, annotator_name='gold')\n",
    "\n",
    "print \"Gold [TRAIN]\", L_gold_train.size\n",
    "print \"Gold [DEV]  \", L_gold_dev.size\n",
    "print \"Gold [TEST] \", L_gold_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_doc_ids_by_split(session, split):\n",
    "    '''\n",
    "    Given a candidate set split, return all corresponding parent document ids\n",
    "    '''\n",
    "    q1 = session.query(Candidate.id).filter(Candidate.split == split).subquery()\n",
    "    q2 = session.query(PainLocation.pain_id).filter(Candidate.id.in_(q1)).subquery()\n",
    "    q3 = session.query(Span.sentence_id).filter(Span.id.in_(q2)).subquery()\n",
    "    rows = session.query(Sentence.document_id).filter(Sentence.id.in_(q3)).distinct()\n",
    "    #items = session.query(Document).filter(Document.id.in_(q4)).all()\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "documents = session.query(Document).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "63\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "print len(train_cands)\n",
    "print len(dev_cands)\n",
    "print len(test_cands)\n",
    "\n",
    "candidates = train_cands + dev_cands + test_cands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "from extractlib.relations.anatomy_pain import *\n",
    "relations = AnatomyPainRelation(candidates, data_root=\"../data/\")\n",
    "lfs = relations.lfs\n",
    "print len(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeler = LabelAnnotator(lfs=lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_train = labeler.apply(split=0, parallelism=1)\n",
    "L_dev   = labeler.apply_existing(split=1, parallelism=1)\n",
    "L_test  = labeler.apply_existing(split=2, parallelism=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Function Empirical Accuracy Statistics\n",
    "Since we have labeled training data, we can examine empirical statistics for labeling function performance. Good labeling function design requires than any heuristic be correct with probablity better than random chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_pro_re_nata</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031111</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_negated</th>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_hypothetical</th>\n",
       "      <td>2</td>\n",
       "      <td>0.182222</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_denies</th>\n",
       "      <td>3</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_history_of</th>\n",
       "      <td>4</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_long_term_history_of</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_compound_words</th>\n",
       "      <td>6</td>\n",
       "      <td>0.248889</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_pref_arg_attachment</th>\n",
       "      <td>7</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_long_distance_attachment</th>\n",
       "      <td>8</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.151111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_accept_header</th>\n",
       "      <td>9</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_reject_header</th>\n",
       "      <td>10</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_breaking_char_inbetween</th>\n",
       "      <td>11</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.297778</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_chronic_pain</th>\n",
       "      <td>12</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_pain_meds</th>\n",
       "      <td>13</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_intensity</th>\n",
       "      <td>14</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_past_perfect_tense</th>\n",
       "      <td>15</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_linking_verbs</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_action_verbs</th>\n",
       "      <td>17</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_list_side_effects</th>\n",
       "      <td>18</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.062222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_instructions</th>\n",
       "      <td>19</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_stopwords</th>\n",
       "      <td>20</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_arg_is_header</th>\n",
       "      <td>21</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_wsd_back</th>\n",
       "      <td>22</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_temporal_recent</th>\n",
       "      <td>23</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_wsd_anatomy_compound_words</th>\n",
       "      <td>24</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_non_modifier</th>\n",
       "      <td>25</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_contains_prepositional_phrase</th>\n",
       "      <td>26</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_patient_presents</th>\n",
       "      <td>27</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   j  Coverage  Overlaps  Conflicts  TP  FP  \\\n",
       "LF_pro_re_nata                     0  0.031111  0.008889   0.000000   0   0   \n",
       "LF_negated                         1  0.200000  0.120000   0.004444   0   0   \n",
       "LF_hypothetical                    2  0.182222  0.173333   0.000000   0   0   \n",
       "LF_denies                          3  0.111111  0.093333   0.004444   0   0   \n",
       "LF_history_of                      4  0.004444  0.000000   0.000000   0   0   \n",
       "LF_long_term_history_of            5  0.000000  0.000000   0.000000   0   0   \n",
       "LF_compound_words                  6  0.248889  0.106667   0.026667  52   4   \n",
       "LF_pref_arg_attachment             7  0.311111  0.266667   0.022222   0   0   \n",
       "LF_long_distance_attachment        8  0.160000  0.151111   0.000000   0   0   \n",
       "LF_accept_header                   9  0.044444  0.044444   0.004444   9   1   \n",
       "LF_reject_header                  10  0.097778  0.097778   0.008889   0   0   \n",
       "LF_breaking_char_inbetween        11  0.311111  0.297778   0.008889   0   0   \n",
       "LF_chronic_pain                   12  0.013333  0.013333   0.000000   3   0   \n",
       "LF_pain_meds                      13  0.026667  0.026667   0.017778   0   0   \n",
       "LF_intensity                      14  0.040000  0.035556   0.008889   7   2   \n",
       "LF_past_perfect_tense             15  0.004444  0.004444   0.000000   0   0   \n",
       "LF_linking_verbs                  16  0.000000  0.000000   0.000000   0   0   \n",
       "LF_action_verbs                   17  0.013333  0.013333   0.013333   1   2   \n",
       "LF_list_side_effects              18  0.062222  0.062222   0.000000   0   0   \n",
       "LF_instructions                   19  0.040000  0.040000   0.000000   0   0   \n",
       "LF_stopwords                      20  0.004444  0.000000   0.000000   0   0   \n",
       "LF_arg_is_header                  21  0.004444  0.004444   0.004444   0   0   \n",
       "LF_wsd_back                       22  0.004444  0.004444   0.000000   0   0   \n",
       "LF_temporal_recent                23  0.022222  0.022222   0.008889   3   2   \n",
       "LF_wsd_anatomy_compound_words     24  0.013333  0.008889   0.004444   0   0   \n",
       "LF_non_modifier                   25  0.013333  0.013333   0.000000   0   0   \n",
       "LF_contains_prepositional_phrase  26  0.008889  0.004444   0.004444   2   0   \n",
       "LF_patient_presents               27  0.022222  0.022222   0.004444   4   1   \n",
       "\n",
       "                                  FN  TN  Empirical Acc.  \n",
       "LF_pro_re_nata                     0   7        1.000000  \n",
       "LF_negated                         1  44        0.977778  \n",
       "LF_hypothetical                    0  41        1.000000  \n",
       "LF_denies                          1  24        0.960000  \n",
       "LF_history_of                      0   1        1.000000  \n",
       "LF_long_term_history_of            0   0             NaN  \n",
       "LF_compound_words                  0   0        0.928571  \n",
       "LF_pref_arg_attachment             4  66        0.942857  \n",
       "LF_long_distance_attachment        2  33        0.942857  \n",
       "LF_accept_header                   0   0        0.900000  \n",
       "LF_reject_header                   2  20        0.909091  \n",
       "LF_breaking_char_inbetween         3  66        0.956522  \n",
       "LF_chronic_pain                    0   0        1.000000  \n",
       "LF_pain_meds                       5   1        0.166667  \n",
       "LF_intensity                       0   0        0.777778  \n",
       "LF_past_perfect_tense              0   1        1.000000  \n",
       "LF_linking_verbs                   0   0             NaN  \n",
       "LF_action_verbs                    0   0        0.333333  \n",
       "LF_list_side_effects               0  14        1.000000  \n",
       "LF_instructions                    0   9        1.000000  \n",
       "LF_stopwords                       0   1        1.000000  \n",
       "LF_arg_is_header                   1   0        0.000000  \n",
       "LF_wsd_back                        0   1        1.000000  \n",
       "LF_temporal_recent                 0   0        0.600000  \n",
       "LF_wsd_anatomy_compound_words      0   3        1.000000  \n",
       "LF_non_modifier                    0   3        1.000000  \n",
       "LF_contains_prepositional_phrase   0   0        1.000000  \n",
       "LF_patient_presents                0   0        0.800000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats(session, labels=L_gold_train.toarray().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Generative Model\n",
    "Grid search for tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RandomSearch search of size 3. Search space size = 4.\n",
      "============================================================\n",
      "[1] Testing step_size = 4.44e-05, decay = 9.00e-01, epochs = 500, reg_param = 1.00e-02, reg_type = 1\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.808510638298\n",
      "[GenerativeModel] Model saved as <GenerativeModel_0>.\n",
      "============================================================\n",
      "[2] Testing step_size = 4.44e-05, decay = 9.00e-01, epochs = 200, reg_param = 1.00e-03, reg_type = 1\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.808510638298\n",
      "============================================================\n",
      "[3] Testing step_size = 4.44e-05, decay = 9.00e-01, epochs = 500, reg_param = 1.00e-03, reg_type = 1\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.808510638298\n",
      "[GenerativeModel] Model <GenerativeModel_0> loaded.\n",
      "CPU times: user 24.5 s, sys: 86.8 ms, total: 24.5 s\n",
      "Wall time: 24.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_size</th>\n",
       "      <th>decay</th>\n",
       "      <th>epochs</th>\n",
       "      <th>reg_param</th>\n",
       "      <th>reg_type</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.9</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.9</td>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step_size  decay  epochs  reg_param  reg_type     Prec.      Rec.        F1\n",
       "0   0.000044    0.9     500      0.010         1  0.826087  0.791667  0.808511\n",
       "1   0.000044    0.9     200      0.001         1  0.826087  0.791667  0.808511\n",
       "2   0.000044    0.9     500      0.001         1  0.826087  0.791667  0.808511"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "# use grid search to optimize the generative model\n",
    "step_size_param     = ListParameter('step_size', [0.01 / L_train.shape[0]])\n",
    "decay_param         = ListParameter('decay', [0.9])\n",
    "epochs_param        = ListParameter('epochs', [200, 500])\n",
    "reg_param           = ListParameter('reg_param', [0.001, 0.01])\n",
    "reg_type            = ListParameter('reg_type', [1])\n",
    "prior_param         = ListParameter('LF_acc_prior_weight_default', [1.0, 0.9, 0.8])\n",
    "\n",
    "# search for the best model\n",
    "param_grid = [step_size_param, decay_param, epochs_param, reg_param, reg_type, prior_param]\n",
    "searcher = RandomSearch(GenerativeModel, param_grid, L_train, n=5, lf_propensity=True)\n",
    "%time gen_model, run_stats = searcher.fit(L_dev, L_gold_dev, deps=set())\n",
    "\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Labeling Function Accuracy Weights\n",
    "These are the accuracy factor weights learned during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc. Factor Weight</th>\n",
       "      <th>LF-NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.893885</td>\n",
       "      <td>LF_pro_re_nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.924052</td>\n",
       "      <td>LF_negated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.921992</td>\n",
       "      <td>LF_hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.908960</td>\n",
       "      <td>LF_denies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.892476</td>\n",
       "      <td>LF_history_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.892203</td>\n",
       "      <td>LF_long_term_history_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.926660</td>\n",
       "      <td>LF_compound_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.945686</td>\n",
       "      <td>LF_pref_arg_attachment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.920323</td>\n",
       "      <td>LF_long_distance_attachment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.897945</td>\n",
       "      <td>LF_accept_header</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.908230</td>\n",
       "      <td>LF_reject_header</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.948254</td>\n",
       "      <td>LF_breaking_char_inbetween</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.893685</td>\n",
       "      <td>LF_chronic_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.892674</td>\n",
       "      <td>LF_pain_meds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.896663</td>\n",
       "      <td>LF_intensity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.892943</td>\n",
       "      <td>LF_past_perfect_tense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.891483</td>\n",
       "      <td>LF_linking_verbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.893450</td>\n",
       "      <td>LF_action_verbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.901085</td>\n",
       "      <td>LF_list_side_effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.897308</td>\n",
       "      <td>LF_instructions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.889870</td>\n",
       "      <td>LF_stopwords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.893370</td>\n",
       "      <td>LF_arg_is_header</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.890915</td>\n",
       "      <td>LF_wsd_back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.893794</td>\n",
       "      <td>LF_temporal_recent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.893728</td>\n",
       "      <td>LF_wsd_anatomy_compound_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.891372</td>\n",
       "      <td>LF_non_modifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.897748</td>\n",
       "      <td>LF_contains_prepositional_phrase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.894681</td>\n",
       "      <td>LF_patient_presents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Acc. Factor Weight                           LF-NAME\n",
       "0             0.893885                    LF_pro_re_nata\n",
       "1             0.924052                        LF_negated\n",
       "2             0.921992                   LF_hypothetical\n",
       "3             0.908960                         LF_denies\n",
       "4             0.892476                     LF_history_of\n",
       "5             0.892203           LF_long_term_history_of\n",
       "6             0.926660                 LF_compound_words\n",
       "7             0.945686            LF_pref_arg_attachment\n",
       "8             0.920323       LF_long_distance_attachment\n",
       "9             0.897945                  LF_accept_header\n",
       "10            0.908230                  LF_reject_header\n",
       "11            0.948254        LF_breaking_char_inbetween\n",
       "12            0.893685                   LF_chronic_pain\n",
       "13            0.892674                      LF_pain_meds\n",
       "14            0.896663                      LF_intensity\n",
       "15            0.892943             LF_past_perfect_tense\n",
       "16            0.891483                  LF_linking_verbs\n",
       "17            0.893450                   LF_action_verbs\n",
       "18            0.901085              LF_list_side_effects\n",
       "19            0.897308                   LF_instructions\n",
       "20            0.889870                      LF_stopwords\n",
       "21            0.893370                  LF_arg_is_header\n",
       "22            0.890915                       LF_wsd_back\n",
       "23            0.893794                LF_temporal_recent\n",
       "24            0.893728     LF_wsd_anatomy_compound_words\n",
       "25            0.891372                   LF_non_modifier\n",
       "26            0.897748  LF_contains_prepositional_phrase\n",
       "27            0.894681               LF_patient_presents"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf_accs = []\n",
    "for name,acc in zip([lf.__name__ for lf in lfs], gen_model.weights.lf_accuracy):\n",
    "    lf_accs.append({\"LF-NAME\":name, \"Acc. Factor Weight\":acc})\n",
    "pd.DataFrame(lf_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x123ba00d0>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBgAAAF1CAYAAABCs1lKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABgmMAAAAADD/j/nYNA5KbqZkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123876e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "df = pd.DataFrame(data=train_marginals, columns=['marginals'])\n",
    "pd.DataFrame.hist(df,range=(0.0, 1.0),bins=20, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "def majority_vote(labels, gold_labels, title=\"Majority Vote\"):\n",
    "    \n",
    "    mv = np.sum(labels,axis=1)\n",
    "    mv[mv > 0] = 1\n",
    "    mv[mv <= 0] = -1\n",
    "    \n",
    "    y_pred = np.ravel(mv)\n",
    "    y_true = gold_labels.toarray()\n",
    "    \n",
    "    print \"=\" * 40\n",
    "    print title\n",
    "    print \"=\" * 40\n",
    "    pos, neg = list(gold_labels).count(1),float(list(gold_labels).count(-1))\n",
    "    print \"pos/neg   {:.2f} {:.2f}\".format(pos/(pos+neg), neg/(pos+neg))\n",
    "    print \"precision {:.2f}\".format( 100 * precision_score(y_true, y_pred) )\n",
    "    print \"recall    {:.2f}\".format( 100 * recall_score(y_true, y_pred) )\n",
    "    print \"f1        {:.2f}\".format( 100 * f1_score(y_true, y_pred) )\n",
    "    print \"-\" * 40\n",
    "\n",
    "def score(marginals, gold_labels, title=\"\"):\n",
    "    y_pred = [1 if marginals[i] > 0.5 else -1 for i in range(0,len(marginals))]\n",
    "    y_true = gold_labels.toarray()\n",
    "    \n",
    "    print \"=\" * 40\n",
    "    print title\n",
    "    print \"=\" * 40\n",
    "    pos,neg = list(gold_labels).count(1),float(list(gold_labels).count(-1))\n",
    "    print \"pos/neg   {:.2f} {:.2f}\".format(pos/(pos+neg), neg/(pos+neg))\n",
    "    print \"precision {:.2f}\".format( 100 * precision_score(y_true, y_pred) )\n",
    "    print \"recall    {:.2f}\".format( 100 * recall_score(y_true, y_pred) )\n",
    "    print \"f1        {:.2f}\".format( 100 * f1_score(y_true, y_pred) )\n",
    "    print \"-\" * 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set: Majority Vote vs. Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Majority Vote\n",
      "========================================\n",
      "pos/neg   0.32 0.68\n",
      "precision 91.07\n",
      "recall    71.83\n",
      "f1        80.31\n",
      "----------------------------------------\n",
      "========================================\n",
      "Generative Model\n",
      "========================================\n",
      "pos/neg   0.32 0.68\n",
      "precision 90.32\n",
      "recall    78.87\n",
      "f1        84.21\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def mv_vs_gen(marginals, L_mat, gold):\n",
    "    majority_vote(L_mat, gold)\n",
    "    score(marginals, gold, \"Generative Model\")\n",
    "    \n",
    "    \n",
    "mv_vs_gen(train_marginals, L_train, L_gold_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Set: Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Majority Vote\n",
      "========================================\n",
      "pos/neg   0.38 0.62\n",
      "precision 82.61\n",
      "recall    79.17\n",
      "f1        80.85\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "majority_vote(L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set: Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Majority Vote\n",
      "========================================\n",
      "pos/neg   0.27 0.73\n",
      "precision 86.84\n",
      "recall    71.74\n",
      "f1        78.57\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "majority_vote(L_test, L_gold_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
