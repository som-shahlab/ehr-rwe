{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Training Sets with Weak Supervision\n",
    "In this tutorial, we'll build a `Pain-At` relation training set using weakly superivsed methods. This notebook covers: \n",
    "- Loading pre-processed documents\n",
    "- Generating relational candidates \n",
    "- Applying labeling functions\n",
    "- Training a Snorkel Label Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../../ehr-rwe/')\n",
    "\n",
    "import glob\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load MIMIC-III Documents\n",
    "We assume documents have already been preprocessed and dumped into JSON format. See `preprocessing/README.md` for details.\n",
    "\n",
    "You will need access to MIMIC-III data to run this notebook. See https://mimic.physionet.org/gettingstarted/access/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rwe import dataloader\n",
    "\n",
    "#inputdir = '/Users/fries/Desktop/clef-rwe/'\n",
    "inputdir = '/Users/fries/Desktop/ehr-notes/'\n",
    "\n",
    "corpus = dataloader(glob.glob(f'{inputdir}/*.json'))\n",
    "\n",
    "print(f'Loaded {len(corpus)} documents')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Candidates\n",
    "\n",
    "This is an example pipeline for generating `Pain-At` relation candidates. For simplicity's sake, we use a dictionary-based method to tag our initial `Anatomy` and `Pain` entities. \n",
    "\n",
    "### Timing Benchmarks \n",
    "\n",
    "- 50,000 MIMIC-III documents\n",
    "- 4 core MacBook Pro 2.5Ghz mid-2015\n",
    "\n",
    "| N Documents   | N Cores | Time |\n",
    "|---------------|---------|----------------|\n",
    "| 299           | 4       | 17 seconds |\n",
    "| 10,000        | 4       | 3.33 minutes  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rwe.utils import load_dict\n",
    "from rwe.labelers.taggers import (\n",
    "    ResetTags, DictionaryTagger, RelationTagger, \n",
    "    NegExTagger, HypotheticalTagger, SectionHeaderTagger,\n",
    "    ParentSectionTagger\n",
    ")\n",
    "\n",
    "dict_pain = load_dict('../data/dicts/pain/pain.txt')\n",
    "dict_anat = load_dict('../data/dicts/anatomy/anat.bz2')\n",
    "\n",
    "pipeline = {\n",
    "    # clear any previous runs\n",
    "    \"reset\"   : ResetTags(),\n",
    "    \n",
    "    # concepts\n",
    "    \"pain\"     : DictionaryTagger({'pain': dict_pain}),\n",
    "    \"anatomy\"  : DictionaryTagger({'anatomy': dict_anat}),\n",
    "    \"sections\" : SectionHeaderTagger(),\n",
    "    \n",
    "    # attributes / primitives\n",
    "    \"negation\"     : NegExTagger(targets=['pain'], data_root=\"../data/dicts/negex/\"),\n",
    "    \"hypothetical\" : HypotheticalTagger(targets=['pain']),\n",
    "    \"headers\"      : ParentSectionTagger(targets=['pain']),\n",
    "    \n",
    "    # relations\n",
    "    \"pain-at\" : RelationTagger('pain-at', ('pain', 'anatomy'))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from rwe.labelers import TaggerPipelineServer\n",
    "\n",
    "tagger = TaggerPipelineServer(num_workers=4)\n",
    "documents = tagger.apply(pipeline, [corpus])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rwe.utils import build_candidate_set, load_gold\n",
    "\n",
    "fpath = \"../data/annotations/mimic.gold.final.tsv\"\n",
    "gold = load_gold(fpath, documents[0], ('part-at', ('pain','anatomy')))\n",
    "\n",
    "Xs = build_candidate_set(documents[0], \"pain-at\")\n",
    "Ys = [gold[x] if x in gold else 0 for x in Xs]\n",
    "Ys = [y if y == 1 else 2 for y in Ys]\n",
    "\n",
    "print(\"Class Balance\")\n",
    "print(f'Positive: {Ys.count(1)} ({Ys.count(1)/len(Ys)*100:2.1f})%')\n",
    "print(f'Negative: {Ys.count(2)} ({Ys.count(2)/len(Ys)*100:2.1f})%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from rwe.labelers.taggers import get_left_span, get_right_span, get_between_span\n",
    "\n",
    "def dict_matches(span, dictionary):\n",
    "    matches = []\n",
    "    toks = span.get_attrib_tokens('words')\n",
    "    for i in range(len(toks)):\n",
    "        for j in range(i+1, len(toks)):\n",
    "            term = ' '.join(toks[i:j]).lower()\n",
    "            if term in dictionary:\n",
    "                matches.append(term)\n",
    "    return matches\n",
    "\n",
    "ABSTAIN  = 0\n",
    "NEGATIVE = 2\n",
    "POSITIVE = 1\n",
    "\n",
    "neg_rgx = re.compile(\n",
    "    r'''\\b(insensitivity|paresthesias|paresthesia|sensitivity|tenderness|discomfort|heaviness|sensitive|itchiness|tightness|throbbing|numbness|tingling|cramping|coldness|soreness|painful|hurting|itching|burning|tender|buring|aching|hurts|aches|pains|hurt|pain|ache|achy|numb)\\b''',\n",
    "    re.I\n",
    ")\n",
    "\n",
    "def LF_is_negated(x):\n",
    "    return NEGATIVE if 'negated' in x.pain.props else ABSTAIN\n",
    "\n",
    "def LF_is_hypothetical(x):\n",
    "    return NEGATIVE if 'hypothetical' in x.pain.props else ABSTAIN\n",
    "\n",
    "def LF_section_headers(x):\n",
    "    sections = {\n",
    "        'past medical history': NEGATIVE,\n",
    "        'chief complaint': POSITIVE,\n",
    "        'discharge instructions': NEGATIVE,\n",
    "        'discharge condition': NEGATIVE\n",
    "    }\n",
    "    header = x.pain.props['section'].text.lower() if x.pain.props['section'] else None\n",
    "    return ABSTAIN if header not in sections else sections[header]\n",
    "\n",
    "#def LF_contiguous(x):\n",
    "#    return POSITIVE if not get_between_span(x.pain, x.anatomy) else ABSTAIN\n",
    "\n",
    "def LF_contiguous(x):\n",
    "    v = not get_between_span(x.pain, x.anatomy)\n",
    "    v &= not 'negated' in x.pain.props\n",
    "    v &= not 'hypothetical' in x.pain.props\n",
    "    return POSITIVE if v else ABSTAIN\n",
    "\n",
    "def LF_distant_args(x):\n",
    "    span = get_between_span(x.pain, x.anatomy)\n",
    "    n_toks = len(span.get_attrib_tokens('words')) if span else 0\n",
    "    return NEGATIVE if n_toks > 10 else ABSTAIN\n",
    "    \n",
    "def LF_between_terms(x):\n",
    "    \"\"\"Reject if some key terms occur between arguments.\"\"\"\n",
    "    span = get_between_span(x.pain, x.anatomy)\n",
    "    if not span:\n",
    "        return ABSTAIN\n",
    "    # negation term      \n",
    "    flag = neg_rgx.search(span.text) is not None\n",
    "    # anatomical term \n",
    "    flag |= len(dict_matches(span, dict_anat)) > 0\n",
    "    return NEGATIVE if flag else ABSTAIN\n",
    "\n",
    "def LF_complains_of(x):\n",
    "    rgx = re.compile(r'''\\b(complain(s*|ing*) of)\\b''', re.I)\n",
    "    is_negated = 'negated' in x.pain.props\n",
    "    is_complains_of = rgx.search(get_left_span(x.pain).text, re.I) is not None\n",
    "    return POSITIVE if not is_negated and is_complains_of else ABSTAIN\n",
    "    \n",
    "\n",
    "lfs = [\n",
    "    LF_is_negated,\n",
    "    LF_is_hypothetical,\n",
    "    LF_section_headers,\n",
    "    LF_contiguous,\n",
    "    LF_distant_args,\n",
    "    LF_between_terms,\n",
    "    LF_complains_of\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "            \n",
    "\n",
    "# # for x in Xs:\n",
    "# #     v = LF_between_terms(x)\n",
    "# #     print(v)\n",
    "\n",
    "# x = Xs[10]\n",
    "# span = get_between_span(x.pain, x.anatomy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from rwe.labelers import LabelingServer\n",
    "\n",
    "labeler = LabelingServer(num_workers=4)\n",
    "Ls = labeler.apply(lfs, [Xs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rwe.analysis import lf_summary\n",
    "\n",
    "lf_summary(Ls[0], Y=Ys, lf_names=[lf.__name__ for lf in lfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rwe.visualization.analysis import view_conflicts, view_label_matrix, view_overlaps\n",
    "\n",
    "view_overlaps(Ls[0], normalize=False)\n",
    "view_label_matrix(Ls[0])\n",
    "view_conflicts(Ls[0], normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Snorkel Label Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sparse matrix to new Snorkel format\n",
    "\n",
    "def convert_label_matrix(L):\n",
    "    L = L.toarray().copy()\n",
    "    L[L == 0] = -1\n",
    "    L[L == 2] = 0\n",
    "    return L\n",
    "\n",
    "\n",
    "Ls_hat = [\n",
    "    convert_label_matrix(Ls[0])\n",
    "]\n",
    "\n",
    "Ys_hat = [\n",
    "    np.array([0 if y == 2 else 1 for y in Ys])\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "lr = 0.01\n",
    "l2 = 0.001\n",
    "prec_init = 0.9\n",
    "\n",
    "label_model = LabelModel(cardinality=2, device='cpu', verbose=True)\n",
    "label_model.fit(L_train=Ls_hat[0], \n",
    "                n_epochs=1000, \n",
    "                lr=lr,\n",
    "                l2=l2,\n",
    "                prec_init=prec_init,\n",
    "                optimizer='adam',\n",
    "                log_freq=100)\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "label_model.score(L=Ls_hat[0], Y=Ys_hat[0], metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 (bert)",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
