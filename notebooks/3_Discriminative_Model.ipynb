{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Learning to Extract Pain Outcomes from Clinical Text without Labeled Data\n",
    "## II: Discriminative Model\n",
    "\n",
    "We train 2 standard discriminative model:\n",
    "\n",
    "- Sparse Logisitic Regression\n",
    "- Bidirectional Long Short Term Memory (LSTM)\n",
    " \n",
    "Logistic regression requires manual feature engineering while the LSTM is a standard, state-of-the-art approach for relation extraction problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numba\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.learning.disc_models.rnn import *\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel.models import candidate_subclass, Document, Sentence, Candidate, Span\n",
    "from snorkel.learning import GenerativeModel\n",
    "from rwe.labelers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "session = SnorkelSession()\n",
    "\n",
    "try:\n",
    "    PainLocation = candidate_subclass('PainLocation', ['pain', 'anatomy'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load Candidates and Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates [TRAIN] 225\n",
      "Candidates [DEV]   63\n",
      "Candidates [TEST]  168\n",
      "Gold [TRAIN] 225\n",
      "Gold [DEV]   63\n",
      "Gold [TEST]  168\n"
     ]
    }
   ],
   "source": [
    "train_cands = session.query(Candidate).filter(Candidate.split == 0).order_by(Candidate.id).all()\n",
    "dev_cands   = session.query(Candidate).filter(Candidate.split == 1).order_by(Candidate.id).all()\n",
    "test_cands  = session.query(Candidate).filter(Candidate.split == 2).order_by(Candidate.id).all()\n",
    "\n",
    "L_gold_train = load_gold_labels(session, split=0, annotator_name='gold')\n",
    "L_gold_dev   = load_gold_labels(session, split=1, annotator_name='gold')\n",
    "L_gold_test  = load_gold_labels(session, split=2, annotator_name='gold')\n",
    "\n",
    "print \"Candidates [TRAIN]\", len(train_cands)\n",
    "print \"Candidates [DEV]  \", len(dev_cands)\n",
    "print \"Candidates [TEST] \", len(test_cands)\n",
    "\n",
    "print \"Gold [TRAIN]\", L_gold_train.shape[0]\n",
    "print \"Gold [DEV]  \", L_gold_dev.shape[0]\n",
    "print \"Gold [TEST] \", L_gold_test.shape[0]\n",
    "\n",
    "# Depending on your choice of parser, some candidates might be identified that were not originally\n",
    "# labeled in our gold test set. This hack just sets those unknown labels to negative\n",
    "L_gold_train[L_gold_train == 0] = -1\n",
    "L_gold_dev[L_gold_dev == 0]     = -1\n",
    "L_gold_test[L_gold_test == 0]   = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "documents = session.query(Document).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "63\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "print len(train_cands)\n",
    "print len(dev_cands)\n",
    "print len(test_cands)\n",
    "\n",
    "candidates = train_cands + dev_cands + test_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 labeling functions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rwe.labelers import *\n",
    "\n",
    "# get our pain/anatomy relation labeling functions\n",
    "lfs = get_labeling_functions(\"pain_anatomy\")\n",
    "\n",
    "print \"Loaded {} labeling functions\\n\".format(len(lfs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 25)\n",
      "(63, 25)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "\n",
    "labeler = LabelAnnotator(lfs=lfs)\n",
    "L_train = labeler.load_matrix(session, split=0)\n",
    "L_dev   = labeler.load_matrix(session, split=1)\n",
    "\n",
    "print L_train.shape\n",
    "print L_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sparse Logistic Regression\n",
    "\n",
    "### Create Features\n",
    "This uses a standard NLP feature generation library using lemmatization, POS tags, and sentence dependency parsing to generate candidate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import FeatureAnnotator\n",
    "from rwe.features import hybrid_span_mention_ftrs\n",
    "\n",
    "featurizer = FeatureAnnotator(hybrid_span_mention_ftrs)\n",
    "\n",
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev   = featurizer.load_matrix(session, split=1)\n",
    "F_test  = featurizer.load_matrix(session, split=2)\n",
    "\n",
    "F_train = F_train if F_train.size != 0 else featurizer.apply(split=0)\n",
    "F_dev   = F_dev if F_dev.size != 0 else featurizer.apply_existing(split=1)\n",
    "F_test  = F_test if F_test.size != 0 else featurizer.apply_existing(split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Supervised Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,recall_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel.learning.utils import MentionScorer\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train Discriminitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RandomSearch search of size 5. Search space size = 8.\n",
      "============================================================\n",
      "[1] Testing step_size = 4.44e-05, lr = 1.00e-02, l1_penalty = 1.00e-04, l2_penalty = 1.00e-04, rebalance = 5.00e-01\n",
      "============================================================\n",
      "disc_learning: random seed 1234\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=174  #epochs=500  batch size=174\n",
      "[SparseLogisticRegression] Epoch 0 (0.02s)\tAverage loss=0.937851\n",
      "[SparseLogisticRegression] Epoch 100 (1.53s)\tAverage loss=0.436457\n",
      "[SparseLogisticRegression] Epoch 200 (2.92s)\tAverage loss=0.435393\n",
      "[SparseLogisticRegression] Epoch 300 (4.47s)\tAverage loss=0.435336\n",
      "[SparseLogisticRegression] Epoch 400 (6.03s)\tAverage loss=0.435343\n",
      "[SparseLogisticRegression] Epoch 499 (7.43s)\tAverage loss=0.435346\n",
      "[SparseLogisticRegression] Training done (7.43s)\n",
      "[SparseLogisticRegression] F1 Score: 0.615384615385\n",
      "[SparseLogisticRegression] Model saved in <checkpoints> as <SparseLogisticRegression_0>\n",
      "============================================================\n",
      "[2] Testing step_size = 4.44e-05, lr = 1.00e-02, l1_penalty = 1.00e-02, l2_penalty = 1.00e-04, rebalance = 5.00e-01\n",
      "============================================================\n",
      "disc_learning: random seed 1234\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=174  #epochs=500  batch size=174\n",
      "[SparseLogisticRegression] Epoch 0 (0.02s)\tAverage loss=6.788413\n",
      "[SparseLogisticRegression] Epoch 100 (1.53s)\tAverage loss=6.908366\n",
      "[SparseLogisticRegression] Epoch 200 (2.94s)\tAverage loss=6.858201\n",
      "[SparseLogisticRegression] Epoch 300 (4.52s)\tAverage loss=6.856060\n",
      "[SparseLogisticRegression] Epoch 400 (6.08s)\tAverage loss=6.856655\n",
      "[SparseLogisticRegression] Epoch 499 (7.51s)\tAverage loss=6.856884\n",
      "[SparseLogisticRegression] Training done (7.51s)\n",
      "[SparseLogisticRegression] F1 Score: 0.615384615385\n",
      "============================================================\n",
      "[3] Testing step_size = 4.44e-05, lr = 1.00e-03, l1_penalty = 1.00e-02, l2_penalty = 1.00e-02, rebalance = 5.00e-01\n",
      "============================================================\n",
      "disc_learning: random seed 1234\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=174  #epochs=500  batch size=174\n",
      "[SparseLogisticRegression] Epoch 0 (0.03s)\tAverage loss=7.152168\n",
      "[SparseLogisticRegression] Epoch 100 (1.42s)\tAverage loss=6.996068\n",
      "[SparseLogisticRegression] Epoch 200 (2.96s)\tAverage loss=7.124614\n",
      "[SparseLogisticRegression] Epoch 300 (4.50s)\tAverage loss=7.184466\n",
      "[SparseLogisticRegression] Epoch 400 (5.94s)\tAverage loss=7.215929\n",
      "[SparseLogisticRegression] Epoch 499 (7.50s)\tAverage loss=7.235091\n",
      "[SparseLogisticRegression] Training done (7.50s)\n",
      "[SparseLogisticRegression] F1 Score: 0.666666666667\n",
      "[SparseLogisticRegression] Model saved in <checkpoints> as <SparseLogisticRegression_2>\n",
      "============================================================\n",
      "[4] Testing step_size = 4.44e-05, lr = 1.00e-02, l1_penalty = 1.00e-04, l2_penalty = 1.00e-04, rebalance = 5.00e-01\n",
      "============================================================\n",
      "disc_learning: random seed 1234\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=174  #epochs=500  batch size=174\n",
      "[SparseLogisticRegression] Epoch 0 (0.02s)\tAverage loss=0.937851\n",
      "[SparseLogisticRegression] Epoch 100 (1.42s)\tAverage loss=0.436457\n",
      "[SparseLogisticRegression] Epoch 200 (3.00s)\tAverage loss=0.435393\n",
      "[SparseLogisticRegression] Epoch 300 (4.43s)\tAverage loss=0.435336\n",
      "[SparseLogisticRegression] Epoch 400 (6.00s)\tAverage loss=0.435343\n",
      "[SparseLogisticRegression] Epoch 499 (7.55s)\tAverage loss=0.435346\n",
      "[SparseLogisticRegression] Training done (7.55s)\n",
      "[SparseLogisticRegression] F1 Score: 0.615384615385\n",
      "============================================================\n",
      "[5] Testing step_size = 4.44e-05, lr = 1.00e-02, l1_penalty = 1.00e-04, l2_penalty = 1.00e-04, rebalance = 5.00e-01\n",
      "============================================================\n",
      "disc_learning: random seed 1234\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=174  #epochs=500  batch size=174\n",
      "[SparseLogisticRegression] Epoch 0 (0.03s)\tAverage loss=0.937851\n",
      "[SparseLogisticRegression] Epoch 100 (1.55s)\tAverage loss=0.436457\n",
      "[SparseLogisticRegression] Epoch 200 (2.93s)\tAverage loss=0.435393\n",
      "[SparseLogisticRegression] Epoch 300 (4.45s)\tAverage loss=0.435336\n",
      "[SparseLogisticRegression] Epoch 400 (5.98s)\tAverage loss=0.435343\n",
      "[SparseLogisticRegression] Epoch 499 (7.38s)\tAverage loss=0.435346\n",
      "[SparseLogisticRegression] Training done (7.38s)\n",
      "[SparseLogisticRegression] F1 Score: 0.615384615385\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SparseLogisticRegression_2/SparseLogisticRegression_2-0\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression_2>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>l1_penalty</th>\n",
       "      <th>l2_penalty</th>\n",
       "      <th>rebalance</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step_size     lr  l1_penalty  l2_penalty  rebalance     Prec.      Rec.  \\\n",
       "2   0.000044  0.001      0.0100      0.0100        0.5  0.629630  0.708333   \n",
       "0   0.000044  0.010      0.0001      0.0001        0.5  0.571429  0.666667   \n",
       "1   0.000044  0.010      0.0100      0.0001        0.5  0.571429  0.666667   \n",
       "3   0.000044  0.010      0.0001      0.0001        0.5  0.571429  0.666667   \n",
       "4   0.000044  0.010      0.0001      0.0001        0.5  0.571429  0.666667   \n",
       "\n",
       "         F1  \n",
       "2  0.666667  \n",
       "0  0.615385  \n",
       "1  0.615385  \n",
       "3  0.615385  \n",
       "4  0.615385  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.learning import SparseLogisticRegression\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "num_model_search = 5\n",
    "\n",
    "# use grid search to optimize the generative model\n",
    "step_size_param     = ListParameter('step_size', [0.01 / L_train.shape[0]])\n",
    "decay_param         = ListParameter('lr', [1e-3, 1e-2])\n",
    "l1_param            = ListParameter('l1_penalty', [1e-4, 1e-2])\n",
    "l2_param            = ListParameter('l2_penalty', [1e-4, 1e-2])\n",
    "balance_param       = ListParameter('rebalance', [0.5])\n",
    "\n",
    "# search for the best model\n",
    "param_grid = [step_size_param, decay_param, l1_param, l2_param, balance_param]\n",
    "\n",
    "searcher = RandomSearch(SparseLogisticRegression, param_grid, F_train, \n",
    "                        train_marginals, n=num_model_search, seed=seed)\n",
    "\n",
    "disc_model, run_stats = searcher.fit(X_valid=F_dev, Y_valid=L_gold_dev, n_threads=1, \n",
    "                                     n_epochs=500, print_freq=100)\n",
    "\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import GoldLabel, GoldLabelKey, Label, LabelKey, Feature, FeatureKey, Candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.826\n",
      "Neg. class accuracy: 0.672\n",
      "Precision            0.487\n",
      "Recall               0.826\n",
      "F1                   0.613\n",
      "----------------------------------------\n",
      "TP: 38 | FP: 40 | TN: 82 | FN: 8\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = disc_model.error_analysis(session, F_test, L_gold_test, b=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x122131c90>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122feb090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = disc_model.marginals(F_test)\n",
    "fig, ax = plt.subplots()\n",
    "df = pd.DataFrame(data=m, columns=['marginals'])\n",
    "pd.DataFrame.hist(df,range=(0.0, 1.0),bins=20, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## LSTM\n",
    "\n",
    "Long Short Term Memory (LSTM) models can acheive state-of-the-art performance on many text classification tasks. We'll train a simple bidirectional LSTM model below.\n",
    "\n",
    "In deep learning, hyperparameter tuning is very important and computationally expensive step in training models. For purposes of this tutorial, we've pre-selected some settings so that you can train a model in under 10 minutes. Advanced users can look at our Grid Search Tutorial for more details on choosing these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RandomSearch search of size 5. Search space size = 36.\n",
      "============================================================\n",
      "[1] Testing attn_window = 10, batch_size = 32, lr = 1.00e-03, dropout = 0.00e+00, dim = 50\n",
      "============================================================\n",
      "disc_learning: random seed 1234\n",
      "[reRNN] Training model\n",
      "[reRNN] n_train=213  #epochs=10  batch size=32\n",
      "[reRNN] Epoch 0 (3.12s)\tAverage loss=0.679233\n",
      "[reRNN] Epoch 9 (30.38s)\tAverage loss=0.502762\n",
      "[reRNN] Training done (30.38s)\n",
      "[reRNN] F1 Score: 0.590163934426\n",
      "[reRNN] Model saved in <checkpoints> as <reRNN_0>\n",
      "============================================================\n",
      "[2] Testing attn_window = 10, batch_size = 64, lr = 1.00e-03, dropout = 0.00e+00, dim = 100\n",
      "============================================================\n",
      "disc_learning: random seed 1234\n",
      "[reRNN] Training model\n",
      "[reRNN] n_train=213  #epochs=10  batch size=64\n",
      "[reRNN] Epoch 0 (3.21s)\tAverage loss=0.660391\n",
      "[reRNN] Epoch 9 (43.98s)\tAverage loss=0.527911\n",
      "[reRNN] Training done (43.98s)\n",
      "[reRNN] F1 Score: 0.716981132075\n",
      "[reRNN] Model saved in <checkpoints> as <reRNN_1>\n",
      "============================================================\n",
      "[3] Testing attn_window = 10, batch_size = 64, lr = 1.00e-02, dropout = 0.00e+00, dim = 100\n",
      "============================================================\n",
      "disc_learning: random seed 1234\n",
      "[reRNN] Training model\n",
      "[reRNN] n_train=213  #epochs=10  batch size=64\n",
      "[reRNN] Epoch 0 (3.26s)\tAverage loss=0.728036\n",
      "[reRNN] Epoch 9 (35.06s)\tAverage loss=1.324923\n",
      "[reRNN] Training done (35.06s)\n",
      "[reRNN] F1 Score: 0.341463414634\n",
      "============================================================\n",
      "[4] Testing attn_window = 10, batch_size = 32, lr = 1.00e-04, dropout = 5.00e-01, dim = 50\n",
      "============================================================\n",
      "disc_learning: random seed 1234\n",
      "[reRNN] Training model\n",
      "[reRNN] n_train=213  #epochs=10  batch size=32\n",
      "[reRNN] Epoch 0 (3.09s)\tAverage loss=0.692749\n",
      "[reRNN] Epoch 9 (33.24s)\tAverage loss=0.639104\n",
      "[reRNN] Training done (33.24s)\n",
      "[reRNN] F1 Score: 0.0\n",
      "============================================================\n",
      "[5] Testing attn_window = 10, batch_size = 64, lr = 1.00e-02, dropout = 2.50e-01, dim = 50\n",
      "============================================================\n",
      "disc_learning: random seed 1234\n",
      "[reRNN] Training model\n",
      "[reRNN] n_train=213  #epochs=10  batch size=64\n",
      "[reRNN] Epoch 0 (2.18s)\tAverage loss=0.686146\n",
      "[reRNN] Epoch 9 (26.86s)\tAverage loss=0.463377\n",
      "[reRNN] Training done (26.86s)\n",
      "[reRNN] F1 Score: 0.4\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/reRNN_1/reRNN_1-0\n",
      "[reRNN] Loaded model <reRNN_1>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attn_window</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>dropout</th>\n",
       "      <th>dim</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.716981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.590164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.341463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attn_window  batch_size      lr  dropout  dim     Prec.      Rec.        F1\n",
       "1           10          64  0.0010     0.00  100  0.655172  0.791667  0.716981\n",
       "0           10          32  0.0010     0.00   50  0.486486  0.750000  0.590164\n",
       "4           10          64  0.0100     0.25   50  0.428571  0.375000  0.400000\n",
       "2           10          64  0.0100     0.00  100  0.411765  0.291667  0.341463\n",
       "3           10          32  0.0001     0.50   50  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def get_max_seq_len(cands):\n",
    "    l = 0\n",
    "    for c in cands:\n",
    "        l = max(len(c[0].sentence.words),l)\n",
    "    print \"max seq len\", l\n",
    "    return l\n",
    "\n",
    "attn_window      = ListParameter('attn_window', [10])\n",
    "batch_size_param = ListParameter('batch_size', [32, 64])\n",
    "rate_param       = RangeParameter('lr', 1e-4, 1e-2, step=1, log_base=10)\n",
    "dropout_param    = RangeParameter('dropout', 0.0, 0.5, step=0.25)\n",
    "dim_param        = ListParameter('dim', [50, 100])\n",
    "\n",
    "param_grid = [attn_window, batch_size_param, rate_param, dropout_param, dim_param]\n",
    "searcher = RandomSearch(reRNN, param_grid, train_cands, train_marginals, n=num_model_search, seed=seed)\n",
    "\n",
    "# search for the best model\n",
    "disc_model, run_stats = searcher.fit(X_valid=dev_cands, Y_valid=L_gold_dev, n_threads=1, \n",
    "                                     n_epochs=100, print_freq=10)\n",
    "\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x1292046d0>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123134910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = disc_model.marginals(test_cands)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "df = pd.DataFrame(data=m, columns=['marginals'])\n",
    "pd.DataFrame.hist(df,range=(0.0, 1.0),bins=20, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.565\n",
      "Neg. class accuracy: 0.746\n",
      "Precision            0.456\n",
      "Recall               0.565\n",
      "F1                   0.505\n",
      "----------------------------------------\n",
      "TP: 26 | FP: 31 | TN: 91 | FN: 20\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = disc_model.error_analysis(session, test_cands, L_gold_test, b=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
