{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Complex Symptom Classification\n",
    "## Building Training Sets with Weak Supervision\n",
    "In this tutorial, we'll build a weakly supervised sentence classifier for identfiying evidence of recent international and domestic travel by patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../../ehr-rwe')\n",
    "\n",
    "import glob\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snorkel\n",
    "\n",
    "print(f'Python version {sys.version}')\n",
    "print(f'Snorkel v{snorkel.__version__}')\n",
    "print(f'NumPy v{np.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load EHR Documents\n",
    "\n",
    "This notebook assumes documents have already been preprocessed and dumped into JSON format. See `tutorials/README.md` for details and the `preprocess.py` scripts in `preprocessing/` to create the required JSON files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rwe import dataloader\n",
    "\n",
    "# these notes are restricted to edits made within the first 1 hour of ED admission\n",
    "inputdir = '' # preprocessed JSON doc directory\n",
    "\n",
    "corpus = dataloader(glob.glob(f'{inputdir}/*.json'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Concept Dictionaries\n",
    "For travel, we want some definition of geographic location. Luckly, there are lots of resources for this. In our experience, off-the-shelf NER with models like spaCy perform quite poorly with EHR text, so we'll just load some U.S. Census gazeteer data and manually tag potential geopolitical named entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import re\n",
    "import collections\n",
    "\n",
    "# https://www.usgs.gov/core-science-systems/ngp/board-on-geographic-names/download-gnis-data\n",
    "def load_usgs_gnis_geonames(fpath, sw=None):\n",
    "    data = collections.defaultdict(set)\n",
    "    df = pd.read_csv(fpath,sep='|', chunksize=10000)\n",
    "    for block in df:\n",
    "        for row in block.itertuples():\n",
    "            for term in [row.FEATURE_NAME, f'{row.FEATURE_NAME}, {row.STATE_ALPHA}']:\n",
    "                if term and term not in sw and term.lower() not in sw:\n",
    "                    data[row.FEATURE_CLASS].add(term)\n",
    "            \n",
    "    return dict(data)\n",
    "\n",
    "def load_geonames_countries(fpath, sw=None):\n",
    "    sw = {} if not sw else sw\n",
    "    data = set()\n",
    "    with open(fpath,'r') as fp:\n",
    "        for line in fp:\n",
    "            row = line.strip()\n",
    "            if row[0] == '#':\n",
    "                continue\n",
    "            row = row.split('\\t')\n",
    "            country = row[4].strip().lower() \n",
    "            capital_city = row[5].strip().lower()\n",
    "            for term in [country, capital_city]:\n",
    "                if term and term not in sw and term.lower() not in sw:\n",
    "                    data.add(term)\n",
    "    return data\n",
    "\n",
    "\n",
    "# setup dictionaries and entity typing (for attaching modifiers)\n",
    "dict_root ='../data/supervision/dicts/'\n",
    "\n",
    "# remove names of hospitals and other stopwords\n",
    "# TODO -- remove common first names and surnames (as defined by US Census data) since these\n",
    "# cause a lot of false positive matches in patient notes\n",
    "stopwords = {\n",
    "    'male', 'well', 'unknown', 'likely', 'non', \n",
    "    'rash', 'el camino', 'camino',  'lima',\n",
    "    'mark', 'social', 'felt', 'post', 'sun', \n",
    "}\n",
    "gnis_dict = load_usgs_gnis_geonames(f'{dict_root}/GPE/NationalFile_20200301.txt', sw=stopwords)\n",
    "country_dict = load_geonames_countries(f'{dict_root}/GPE/countryInfo.txt', sw=stopwords)\n",
    "\n",
    "gpe_dict = set(list(gnis_dict['Populated Place']) + list(country_dict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Candidates\n",
    "\n",
    "Some clinical tasks don't neatly fit into an entity tagging framework. Complex symptoms such as travel history cover a range of statements involving travel location, subject of the travel (patient, family, coworker etc), or other nuance. Consider these examples and their class label. \n",
    "\n",
    "- Patient denies recent travel [NEGATIVE]\n",
    "- Returned 1.5 weeks ago from a trip in Italy. [POSITIVE]\n",
    "- Attended a conference in New York City last month. [POSITIVE]\n",
    "- Patient's father recently returned from Italy. [NEGATIVE]\n",
    "- Last week attended a work event and talked with several visitors from China [NEGATIVE]\n",
    "\n",
    "We formulate this task as a sentence classification problem\n",
    "\n",
    "### Clinical Text Markup\n",
    "When writing labeling functions, it's helpful to have access to document markup and other metadata. For example, we might want to know what document section we are currently in (e.g., Past Medical History) or if we have temporal information above an event, such as a date of occurence, we might want to incorporate that information into our labeling heuristics. \n",
    "\n",
    "### Timing Benchmarks \n",
    "\n",
    "- 4 core MacBook Pro 2.5Ghz mid-2015\n",
    "\n",
    "| N Sentences   | N Cores | Time |\n",
    "|---------------|---------|----------------|\n",
    "| 2115          | 4       | 1 minute 10 secs |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rwe.labelers.taggers import (\n",
    "    ResetTags, DocTimeTagger,\n",
    "    DictionaryTagger, HypotheticalTagger, HistoricalTagger,\n",
    "    SectionHeaderTagger, ParentSectionTagger,\n",
    "    Timex3Tagger, Timex3NormalizerTagger, TimeDeltaTagger,\n",
    "    FamilyTagger, PolarityTagger, TextFieldDocTimeTagger\n",
    ")\n",
    "\n",
    "# These are largely note type and institution specific. \n",
    "# TODO: Train a proper header tagger\n",
    "def get_header_dict():\n",
    "    return set([\n",
    "        'Allergen Reactions', 'Attending Attestations', 'Attending Attestions', \n",
    "        'Chief Complaint', 'Clinical Decision Rules', 'Critical Care and Sepsis', \n",
    "        'Critical Care and Sepsis Alert', 'Diagnosis Code', \n",
    "        'ED Course, Data Review & Interpretation', 'ED Treatment', \n",
    "        'Family History', 'HPI', 'History & Physical', 'History From Shared Lists', \n",
    "        'Labs & Imaging', 'Labs ordered', 'Medical Decision Making', 'Medications', \n",
    "        'New Prescriptions', 'Occupational History', 'Past Medical History', \n",
    "        'Patient Active Problem List', 'Patient Active Problem List', \n",
    "        'Physical Exam', 'Prior to Admission Medications', 'Procedures', \n",
    "        'Reason for Hospitalization', 'Recent Labs', 'Review of Systems', \n",
    "        'Social History', 'Substance and Sexual Activity', 'Summary of assessment', \n",
    "        'Tobacco Use', 'Ultrasounds & Procedures'\n",
    "    ])\n",
    "\n",
    "# Major header are typically sections, minor headers are key/value pairs\n",
    "# Physical Exam\n",
    "# EYES: ....\n",
    "# ABD: ....\n",
    "def get_major_section_headers():\n",
    "    return set([\n",
    "        'Clinical Decision Rules', 'Diagnosis Code', \n",
    "        'ED Course, Data Review & Interpretation', 'ED Treatment', 'Family History', \n",
    "        'HPI', 'History & Physical', 'Labs & Imaging', 'Medical Decision Making', \n",
    "        'New Prescriptions', 'Past Medical History', 'Physical Exam', \n",
    "        'Prior to Admission Medications', 'Procedures', 'Review of Systems', \n",
    "        'Social History', 'Summary of assessment'\n",
    "    ])\n",
    "\n",
    "target_entities = ['GPE']\n",
    "\n",
    "# Entity Pipeline\n",
    "pipeline = {\n",
    "    \"reset\"     : ResetTags(),\n",
    "        \n",
    "    # 2. Clinical concepts\n",
    "    #\"headers\"   : SectionHeaderTagger(header_dict=get_header_dict(), \n",
    "    #                                stop_headers={}),\n",
    "    \"concepts\"  : DictionaryTagger({'GPE': gpe_dict}),\n",
    "    \"timex3\"    : Timex3Tagger(),\n",
    "\n",
    "    # Normalize Datetimes\n",
    "    \"doctimes\"  : DocTimeTagger(prop='CREATED_AT', format='%Y-%m-%d %H:%M:%S'),\n",
    "    \"normalize\" : Timex3NormalizerTagger(),\n",
    "\n",
    "    # Concept Modifiers\n",
    "    #\"section\"   : ParentSectionTagger(targets=target_entities + ['TIMEX3'], \n",
    "    #                                 major_headers=None),\n",
    "    #\"tdelta\"    : TimeDeltaTagger(targets=target_entities),\n",
    "    #\"polarity\"  : PolarityTagger(targets=target_entities,\n",
    "    #                          data_root=f\"{dict_root}/negex/\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from rwe.labelers import TaggerPipelineServer\n",
    "\n",
    "tagger = TaggerPipelineServer(num_workers=4)\n",
    "documents = tagger.apply(pipeline, [corpus])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank and Select Candidate Sentences\n",
    "For simplicity and computational efficiency, we represent each document  as the top-k sentences given a query. \n",
    "We use a simple boolean query, but something more sophisticated (embeddings, search engine) works fine too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import collections\n",
    "\n",
    "query_terms = [\n",
    "    'travel', 'returned', 'vacation', 'trip',  'fly', \n",
    "    'flying', 'flew', 'flight', 'airplane', 'plane', 'cruise'\n",
    "] + list(country_dict)\n",
    "query_terms = set(query_terms)\n",
    "print(f'Query Terms: {len(query_terms)}')\n",
    "\n",
    "doc_sent_idx = collections.defaultdict(list)\n",
    "candidates = []\n",
    "\n",
    "for i, doc in enumerate(documents[0]):\n",
    "    for sent in doc.sentences:\n",
    "        terms = list(map(lambda x:x.lower(), sent.words))\n",
    "        if query_terms.intersection(terms):\n",
    "            doc_sent_idx[doc.name].append(len(candidates)) \n",
    "            candidates.append(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Sentence Corpus for Manual Annotation\n",
    "We need *some* hand labeled data to verify our model's output, so we export all of our ranked sentences for manual labeling. In practice, just loading these in Excel and distributing to 2-3 clinical experts works fine (and much faster than a heavy-weight annotation system like BRAT). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_annotation_tsv(candidates, fpath):\n",
    "    data = ['\\t'.join(['','Y','DOC_NAME', 'SENT_IDX', 'TEXT'])]\n",
    "    for i, x in enumerate(candidates):\n",
    "        text = x.text.strip().replace('\\n',' ')\n",
    "        row = [i, '', x.document.name, x.i, text]\n",
    "        row = list(map(str, row))\n",
    "        data.append('\\t'.join(row))\n",
    "    with open(fpath, 'w') as fp:\n",
    "        fp.write('\\n'.join(data))\n",
    "        \n",
    "#export_annotation_tsv(candidates, 'travel.gold.ANNOTATOR.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import pandas as pd\n",
    "\n",
    "fpath = 'travel.gold.ANNOTATOR.tsv'\n",
    "gold = pd.read_csv(fpath, sep='\\t', encoding='latin-1')\n",
    "\n",
    "# build gold index by keys to maintain ordering\n",
    "gold = {(doc_name,sent_i):y for doc_name,sent_i,y in zip(gold.DOC_NAME, gold.SENT_IDX, gold.Y)}\n",
    "\n",
    "Y_gold = []\n",
    "for x in candidates:\n",
    "    key = (x.document.name, x.i)\n",
    "    if key not in gold:\n",
    "        Y_gold.append(-1)\n",
    "    else:\n",
    "        y = int(gold[key]) if not np.isnan(gold[key]) else -1\n",
    "        Y_gold.append(y)\n",
    "\n",
    "Y_gold = np.array(Y_gold)\n",
    "Y_gold[Y_gold == 0] = 2\n",
    "Y_gold[Y_gold == -1] = 0\n",
    "\n",
    "print(f'Neg: {len(Y_gold[Y_gold==2])}')\n",
    "print(f'Pos: {len(Y_gold[Y_gold==1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_index = {doc.name:doc for doc in documents[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define and Apply Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from rwe.labelers.taggers.negex import NegEx \n",
    "from rwe.helpers import (\n",
    "    match_regex, token_distance, \n",
    "    get_left_span, get_right_span\n",
    ")\n",
    "\n",
    "ABSTAIN   = 0\n",
    "TRAVEL    = 1\n",
    "NO_TRAVEL = 2\n",
    "\n",
    "negex = NegEx(f'{dict_root}/negex/')\n",
    "\n",
    "#\n",
    "# Helper Functions\n",
    "#\n",
    "\n",
    "def is_negated(span, window=None):\n",
    "    left = get_left_span(span, window=window)\n",
    "    trigger = match_regex(negex.rgxs['definite']['left'], left)\n",
    "    return True if trigger else False\n",
    "\n",
    "def no_recent_travel(sent):\n",
    "    \"\"\"Explicit statement of no travel\"\"\"\n",
    "    rgx = r'''\\b(travel(s|ed|ing)*|vacation|trip)\\b'''\n",
    "    trigger = match_regex(rgx, sent)\n",
    "    return True if trigger and is_negated(trigger) else False\n",
    "\n",
    "#\n",
    "# Labeling Functions\n",
    "#\n",
    "\n",
    "def LF_travel_mode(s):\n",
    "    \"\"\"Mode of transportation indicating long(er) distance travel\"\"\"\n",
    "    rgx = r'''\\b(flight|fly(ing)*|flew|airplane)\\b'''\n",
    "    return TRAVEL if re.search(rgx, s.text, re.I) else ABSTAIN\n",
    "\n",
    "def LF_cruise_ships(s):\n",
    "    \"\"\"\n",
    "    Cruise ships are more complicated because there are secondary \n",
    "    exposures from clean-up crews and others.\n",
    "    \"\"\"\n",
    "    rgx = r'''((ruby|coral|grand|diamond) princess|celebrity eclipse|(princess|carnival) cruise(s)*)'''\n",
    "    v = re.search(rgx, s.text, re.I) is not None\n",
    "    rgx = r'''(visitor(s)*|friend(s)*|roomate|father|mother|coworker)'''\n",
    "    v &= re.search(rgx, s.text, re.I) is None\n",
    "    return TRAVEL if v else ABSTAIN\n",
    "\n",
    "def LF_old_travel(s):\n",
    "    \"\"\"Ignore travel from time windows outside the COVID-19 pandemic.\"\"\"\n",
    "    rgx = r'''\\b(travel(s|ed|ing)*|vacation|trip)\\b'''\n",
    "    trigger = match_regex(rgx, s)\n",
    "    if not trigger or is_negated(trigger):\n",
    "        return ABSTAIN\n",
    "    \n",
    "    rgx = r'''[1-9]+ (year|week|day)[s]* (ago|prior)'''\n",
    "    right_trigger = match_regex(rgx, get_right_span(trigger))\n",
    "    if not right_trigger:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    return NO_TRAVEL if 'year' in s.text else TRAVEL\n",
    "    \n",
    "def LF_travel(s):\n",
    "    \"\"\"Check for travel terms + simple negation\"\"\"\n",
    "    rgx = r'''\\b(travel(s|ed|ing)*|vacation|trip)\\b'''\n",
    "    trigger = match_regex(rgx, s)\n",
    "    if not trigger:\n",
    "        return ABSTAIN\n",
    "    return TRAVEL if not is_negated(trigger) else NO_TRAVEL\n",
    "\n",
    "def LF_geo_terms(s, time_window_days=120):\n",
    "    \"\"\"\n",
    "    Some mention of travel to a geolocation with \n",
    "    a date in our time window of interest\n",
    "    \"\"\"\n",
    "    # explicit mention of no travel\n",
    "    if no_recent_travel(s):\n",
    "        return NO_TRAVEL\n",
    "    \n",
    "    # how far back to we want to register travel as a risk factor?\n",
    "    anchor_ts = datetime.datetime.now() - datetime.timedelta(days=time_window_days)\n",
    "    # filter out connections (my father returned from China)\n",
    "    rgx = r'''(visitor(s)*|friend(s)*|roomate|father|mother|colleague|co[-]*worker)'''\n",
    "    if re.search(rgx, s.text, re.I):\n",
    "        return ABSTAIN\n",
    "    \n",
    "    # exact all named entities in this sentence\n",
    "    entities = doc_index[s.document.name].annotations[s.i]\n",
    "    if 'GPE' in entities and 'TIMEX3' in entities:\n",
    "        # filter out dates that don't fall in our time window\n",
    "        ts = [t.normalized for t in entities['TIMEX3'] if t.normalized]\n",
    "        if ts and anchor_ts > max(ts):\n",
    "            return NO_TRAVEL\n",
    "        return TRAVEL\n",
    "\n",
    "    return ABSTAIN\n",
    "    \n",
    "def LF_returned(s):\n",
    "    rgx = r''' returned to ([A-Za-z0-9]+\\s*){1,3}hospital'''\n",
    "    if re.search(rgx, s.text, re.I):\n",
    "        return NO_TRAVEL\n",
    "    rgx = r'''returned from'''\n",
    "    return TRAVEL if re.search(rgx, s.text, re.I) else ABSTAIN\n",
    "\n",
    "def LF_motion_sickness(s):\n",
    "    \"\"\"\n",
    "    Discussions of air travel also include prescriptions of medication\n",
    "    for motion sickness\n",
    "    \"\"\"\n",
    "    terms = {}\n",
    "    \n",
    "    \n",
    "def LF_boilerplate(s):\n",
    "    \"\"\"\n",
    "    Catch some copy-n-pasted responses that use 'returned' in the non-trip sense\n",
    "    'I have asked the patient to remain in home isolation until results have returned.'\n",
    "    \"\"\"\n",
    "    # ignore extraneous whitespace\n",
    "    text = re.sub(r'''[\\n\\s]+''', ' ', s.text)\n",
    "    rgx = r'''(result(s)* ([A-Za-z0-9]+\\s*){1,3}returned)'''\n",
    "    if re.search(rgx, text, re.I):\n",
    "        return NO_TRAVEL  \n",
    "    cdc = {'China', 'Iran', 'Italy', 'Japan', 'South Korea'}\n",
    "    if [t in text for t in cdc].count(True) == len(cdc):\n",
    "        return NO_TRAVEL\n",
    "    return ABSTAIN\n",
    "\n",
    "# TODO add more labeling functions \n",
    "lfs = [\n",
    "    LF_travel_mode,\n",
    "    LF_cruise_ships,\n",
    "    LF_old_travel,\n",
    "    LF_travel,\n",
    "    LF_geo_terms,\n",
    "    LF_boilerplate,\n",
    "    LF_returned\n",
    "]\n",
    "\n",
    "# split into train/test sets\n",
    "train_idxs = np.where(Y_gold == 0)\n",
    "test_idxs = np.where(Y_gold != 0)\n",
    "\n",
    "Xs = [\n",
    "    np.array(candidates)[train_idxs], \n",
    "    np.array(candidates)[test_idxs]\n",
    "]\n",
    "\n",
    "Ys = [\n",
    "    Y_gold[np.where(Y_gold == 0)],\n",
    "    Y_gold[np.where(Y_gold != 0)],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply these LFs to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from rwe.labelers import LabelingServer\n",
    "\n",
    "labeler = LabelingServer(num_workers=4)\n",
    "Ls = labeler.apply(lfs, Xs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then examine the accuracy of each of our LFs using the gold labeled data as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rwe.analysis import lf_summary\n",
    "\n",
    "lf_summary(Ls[1], Y=Ys[1], lf_names=[lf.__name__ for lf in lfs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rwe.visualization.analysis import view_conflicts, view_label_matrix, view_overlaps\n",
    "\n",
    "view_overlaps(Ls[1], normalize=False)\n",
    "view_conflicts(Ls[1], normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Snorkel Label Model \n",
    "\n",
    "### The next step is to train a Snorkel Label model using the data labeled with our labeling functions.\n",
    "\n",
    "Note -- we aren't doing any tuning here at all! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sparse matrix to new Snorkel format\n",
    "\n",
    "def convert_label_matrix(L):\n",
    "    L = L.toarray().copy()\n",
    "    L[L == 0] = -1\n",
    "    L[L == 2] = 0\n",
    "    return L\n",
    "\n",
    "\n",
    "Ls_hat = [\n",
    "    convert_label_matrix(Ls[0]),\n",
    "    convert_label_matrix(Ls[1])\n",
    "]\n",
    "\n",
    "Ys_hat = [\n",
    "    [],\n",
    "    np.array([0 if y == 2 else 1 for y in Ys[1]]),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "n = Ls_hat[1].shape[0]\n",
    "lr = 0.001\n",
    "l2 = 0.001\n",
    "prec_init = 0.8\n",
    "mu_eps = 1 / 10 ** np.ceil(np.log10(n))\n",
    "              \n",
    "\n",
    "label_model = LabelModel(cardinality=2, device='cpu', verbose=True)\n",
    "label_model.fit(L_train=Ls_hat[1], \n",
    "                n_epochs=100, \n",
    "                lr=lr,\n",
    "                l2=l2,\n",
    "                prec_init=prec_init,\n",
    "                optimizer='adamax',\n",
    "                log_freq=100,\n",
    "                mu_eps=mu_eps)\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "label_model.score(L=Ls_hat[1], Y=Ys_hat[1], metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def mv(L, break_ties):\n",
    "    \"\"\"Simple majority vote\"\"\"\n",
    "    from statistics import mode\n",
    "    y_hat = []\n",
    "    for row in L:\n",
    "        row = row[row != -1]\n",
    "        try:\n",
    "            l = mode(row)\n",
    "        except:\n",
    "            l = break_ties\n",
    "        y_hat.append(l)\n",
    "    return np.array(y_hat).astype(np.int)\n",
    "\n",
    "mv_pred = mv(Ls_hat[1], 0)\n",
    "y_gold = [1 if y == 1 else 0 for y in Ys[1]]\n",
    "print(classification_report(y_gold, mv_pred))\n",
    "\n",
    "y_pred = label_model.predict(Ls_hat[1])\n",
    "y_pred[y_pred == -1] = 0\n",
    "\n",
    "print(classification_report(y_gold, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Probabalisitic Labels for Unlabeled Data\n",
    "\n",
    "### The last step in this tutorial is to use our labeling model to predict on new data.\n",
    "\n",
    "Now you can load these labels into your end model (LSTM, BERT, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_proba = label_model.predict_proba(Ls_hat[1])\n",
    "Y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
